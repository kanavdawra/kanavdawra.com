{"id":219,"date":"2021-11-26T03:02:13","date_gmt":"2021-11-26T03:02:13","guid":{"rendered":"https:\/\/kanavdawra.com\/?p=219"},"modified":"2021-12-10T04:57:02","modified_gmt":"2021-12-10T04:57:02","slug":"a-robust-explanation-of-handwriting-recognition-crnn","status":"publish","type":"post","link":"https:\/\/kanavdawra.com\/blog\/a-robust-explanation-of-handwriting-recognition-crnn\/","title":{"rendered":"A Robust Explanation of Handwriting Recognition &#8211; CRNN"},"content":{"rendered":"\n<p>What is Handwriting recognition? Well, Handwriting recognition or Handwriting Text Recognition is the ability of a computer to read the text source which is written by hand. As the source is illegible to the computer there are some techniques that give the computer the ability to read the text.<\/p>\n\n\n\n<p>Some are:<\/p>\n\n\n\n<ol type=\"1\"><li>Convolutional Neural Network Method<\/li><li>Semi Incremental Method<\/li><li>Incremental Method<\/li><li>Line and Word Segmentation Method<\/li><li>Part-Based Method<\/li><\/ol>\n\n\n\n<p>There are more but we will learn about the ` Convolutional Neural Network Method`<br><\/p>\n\n\n\n<p>Now let\u2019s begin\u2026<\/p>\n\n\n\n<p>But first<\/p>\n\n\n\n<hr class=\"wp-block-separator\"\/>\n\n\n\n<h3 class=\"wp-block-heading\">A gentle introduction to CNN (Convolutional Neural Network)<\/h3>\n\n\n\n<p>CNN or Convolutional Neural Network is a class of ANN that is used for image analysis but can also be used for Audio, Video, etc.<\/p>\n\n\n\n<p>Since we are dealing with image data CNNs are important but not necessary.<\/p>\n\n\n\n<p>Chris \u2013 We need CNNs when dealing with Image Data.<\/p>\n\n\n\n<p>Kate \u2013 Not necessarily.<\/p>\n\n\n\n<p>Chris \u2013 What? Really.<\/p>\n\n\n\n<p>The job of CNN is not to train the data but to process the image and extract features (like edge detection, etc.) and if we already have those features and images are processed, then we don\u2019t need CNN. In 99.99% of the cases, we do need CNN and if heaven permits you to have a dataset that is already preprocessed you are in LUCK.<\/p>\n\n\n\n<p>Why we need CNN\u2013<\/p>\n\n\n\n<p>Image is a combination of pixels that are nothing, but numbers and we know that our models can only understand numbers<\/p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"327\" src=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/matrix_to_image-1024x327.png\" alt=\"\" class=\"wp-image-220\" srcset=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/matrix_to_image-1024x327.png 1024w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/matrix_to_image-300x96.png 300w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/matrix_to_image-768x245.png 768w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/matrix_to_image-800x255.png 800w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/matrix_to_image.png 1179w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" \/><\/figure>\n\n\n\n<p>Here we can see that a matrix of numbers represents an image.<\/p>\n\n\n\n<p>Now we can feed this into our model directly, but the neural network cannot accept matrix, so we flatten it.<\/p>\n\n\n\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"901\" height=\"70\" src=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/flattend_matrix.png\" alt=\"\" class=\"wp-image-221\" srcset=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/flattend_matrix.png 901w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/flattend_matrix-300x23.png 300w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/flattend_matrix-768x60.png 768w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/flattend_matrix-800x62.png 800w\" sizes=\"(max-width: 901px) 100vw, 901px\" \/><\/figure>\n\n\n\n<p>We get 4X4 or 16 features as input to our neural network layer and train it and we will be done. Now your question will be \u2018Hey wait, where is CNN?\u2019 and your answer will be we don\u2019t need CNN in this case. Remember when I said you only need CNN for image processing and feature extraction. And in this case, there is not much data to do anything.<\/p>\n\n\n\n<p>The problems with this approach are:<\/p>\n\n\n\n<ol type=\"1\"><li>What if our image is <strong>1920 X 1080<\/strong> full HD image or worse a 4k image then in case of full HD image there will be over 2 million features.<\/li><li>We need feature extraction, so our model learns image and not remember it.<\/li><\/ol>\n\n\n\n<p><strong>Let\u2019s see how CNN works-<\/strong><\/p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"548\" src=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/CNN_Architecture-1024x548.jpeg\" alt=\"\" class=\"wp-image-222\" srcset=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/CNN_Architecture-1024x548.jpeg 1024w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/CNN_Architecture-300x161.jpeg 300w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/CNN_Architecture-768x411.jpeg 768w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/CNN_Architecture-1536x822.jpeg 1536w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/CNN_Architecture-800x428.jpeg 800w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/CNN_Architecture.jpeg 1644w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" \/><figcaption><em>Source analyticsvidhya.com<\/em><\/figcaption><\/figure>\n\n\n\n<p>The Image looks very complicated, but it is very easy, we will learn how it works as we progress<\/p>\n\n\n\n<p>Convolution in CNN means the convolutional operations on a matrix which we do by multiplying with another matrix and then add all the values.<\/p>\n\n\n\n<p>Example \u2013<\/p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"341\" src=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/12\/1_convolution_operation-1024x341.png\" alt=\"\" class=\"wp-image-266\" srcset=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/12\/1_convolution_operation-1024x341.png 1024w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/12\/1_convolution_operation-300x100.png 300w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/12\/1_convolution_operation-768x256.png 768w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/12\/1_convolution_operation-800x266.png 800w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/12\/1_convolution_operation.png 1225w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" \/><\/figure>\n\n\n\n<p>This is done in the Conv2D layer in CNN<\/p>\n\n\n\n<p>Here we have extracted the features for our model<\/p>\n\n\n\n<p>To reduce the data size using the MaxPooling layer by getting the maximum values from the matrix using any size matrix in the example below I have used a 2X2 matrix to get the maximum values.<\/p>\n\n\n\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"741\" height=\"291\" src=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/12\/1_max_pooling.png\" alt=\"\" class=\"wp-image-268\" srcset=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/12\/1_max_pooling.png 741w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/12\/1_max_pooling-300x118.png 300w\" sizes=\"(max-width: 741px) 100vw, 741px\" \/><\/figure>\n\n\n\n<p>This is done in the MaxPooling layer.<\/p>\n\n\n\n<p>Now we are done with CNN.<\/p>\n\n\n\n<p>Since we are doing handwriting recognition which does not just image classification but also text recognition. We need to use RNNs<\/p>\n\n\n\n<p>But why?<\/p>\n\n\n\n<p>Why can\u2019t we just do it CNN?<\/p>\n\n\n\n<p>Well&#8230;<\/p>\n\n\n\n<p>Let\u2019s computer reads a text by crunching the numbers the text is \u2018Data has a better idea\u2019 and it guesses the correct characters but the sequence is messed up and outputs &#8216;a&nbsp; shatteerb di aa etda&#8217; we didn\u2019t achieve our task here. So, the sequence is important here and, in every case, where the sequence is important for example Stock market prediction, Human Activity Recognition, Time Series Data, etc. We use RNN<\/p>\n\n\n\n<p>We won\u2019t go too deep into RNN but here we will use Bidirectional LSTM (Long short term memory)<\/p>\n\n\n\n<p>In short, LSTM saves the previous state of the data and predict the next data e.g. input \u2018Data Sci\u2019, output \u2018ence\u2019<\/p>\n\n\n\n<h4 class=\"wp-block-heading\">Now Let\u2019s Start<\/h4>\n\n\n\n<p>I am using a data set from Kaggle <a href=\"https:\/\/www.kaggle.com\/landlord\/handwriting-recognition\" target=\"_blank\" rel=\"noreferrer noopener\">https:\/\/www.kaggle.com\/landlord\/handwriting-recognition<\/a>. You can use any data set, but often people start with `IAM Dataset`<\/p>\n\n\n\n<p>Steps required<\/p>\n\n\n\n<ol type=\"1\"><li>Data Collection<\/li><li>Data Cleaning<\/li><li>Data Preprocessing<\/li><li>Training<\/li><\/ol>\n\n\n\n<h4 class=\"wp-block-heading\">Data Collection<\/h4>\n\n\n\n<p>Download the dataset to your local machine or cloud instance, since we are dealing with image data, we will be playing with image paths. So get all of the paths in a Dataframe.<\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">train=pd.read_csv(config.BASE_DATA_DIR+r'\/written_name_train_v2.csv')\nvalid=pd.read_csv(config.BASE_DATA_DIR+r'\/written_name_validation_v2.csv')\ntest=pd.read_csv(config.BASE_DATA_DIR+r'\/written_name_test_v2.csv')<\/pre>\n\n\n\n<p>config.BASE_DATA_DIR is a constant in the config file. What is a config file? It is a file where we declare all our global variables and other functions. You can find the file in my GitHub repository.<\/p>\n\n\n\n<h4 class=\"wp-block-heading\">Data Cleaning<\/h4>\n\n\n\n<p>We will clean the data set of any missing values which are standard practices.<\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">train.dropna(axis=0,inplace=True,how='any')\ntrain.reset_index(drop=True,inplace=True)\nvalid.dropna(axis=0,inplace=True,how='any')\nvalid.reset_index(drop=True,inplace=True)\ntest.dropna(inplace=True)\ntest.reset_index(drop=True,inplace=True)<\/pre>\n\n\n\n<h4 class=\"wp-block-heading\">Data Preprocessing<\/h4>\n\n\n\n<p>This is arguably the biggest part of the whole project. Here we will prepare our data set for training.<\/p>\n\n\n\n<p>The tasks we need to achieve:<\/p>\n\n\n\n<ul><li>Prepare the Images for training<\/li><li>Prepare the labels for training<\/li><li>Prepare the dataset from the images and labels<\/li><\/ul>\n\n\n\n<h4 class=\"wp-block-heading\">Image Processing<\/h4>\n\n\n\n<p>Steps:<\/p>\n\n\n\n<ol type=\"1\"><li>Read the Image from the path<\/li><li>Decode the Image<\/li><li>Convert it to Float32 (we will see why)<\/li><li>Resize the Image<\/li><li>Transpose the Image<\/li><li>Flip the Image<\/li><\/ol>\n\n\n\n<h5 class=\"wp-block-heading\">Read the Image from the path<\/h5>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">def read_image(path):\n    return tf.io.read_file(path)<\/pre>\n\n\n\n<p>this is a simple method to read the file<\/p>\n\n\n\n<p>but our file is just data and not in any file format for that we need to decode the image<\/p>\n\n\n\n<h5 class=\"wp-block-heading\">Decode the Image<\/h5>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">def decode_image(image, image_type):\n    if image_type == \"jpg\" or \"jpeg\":\n        return tf.io.decode_jpeg(image, channels=config.IMAGE_CHANNELS)\n    elif image_type == \"png\":\n        return tf.io.decode_png(image, channels=config.IMAGE_CHANNELS)\n    else:\n        print(\"Image type must me jpg, jpeg, png\")<\/pre>\n\n\n\n<p>You might have noticed the `channels` argument in ` tf.io.decode_jpeg()` method, But what is that? It specifies whether it is a black and white (channel 1) or coloured image (channel 3). Now that we have decoded the image let\u2019s move on to the next step.<\/p>\n\n\n\n<h5 class=\"wp-block-heading\">Convert it to Float32<\/h5>\n\n\n\n<p>But why? Because we need it in the range of 0 and 1 and we don\u2019t need the values far apart<\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">def convert_image_float32(image):\n\u00a0\u00a0\u00a0 return tf.image.convert_image_dtype(image, tf.float32)<\/pre>\n\n\n\n<p>Now to one of the most important parts resize the image<\/p>\n\n\n\n<h5 class=\"wp-block-heading\">Resize the Image<\/h5>\n\n\n\n<p>There are 2 ways to do an easy way and the correct way (in most cases)<\/p>\n\n\n\n<ul><li>Easy way is without maintaining the aspect ratio<\/li><li>The correct way is with maintaining the aspect ratio<\/li><\/ul>\n\n\n\n<p>But why do we need to maintain the aspect ratio?<\/p>\n\n\n\n<p>Let\u2019s see if we don\u2019t maintain the aspect ratio<\/p>\n\n\n\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"730\" height=\"196\" src=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/distorted_img.png\" alt=\"\" class=\"wp-image-226\" srcset=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/distorted_img.png 730w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/distorted_img-300x81.png 300w\" sizes=\"(max-width: 730px) 100vw, 730px\" \/><\/figure>\n\n\n\n<p>As we can see the image is distorted which will adversely affect our model accuracy. So we need to maintain the aspect ratio and how can we do that while resizing the image.<\/p>\n\n\n\n<p>We do it by adding padding<\/p>\n\n\n\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"517\" height=\"120\" src=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/aspect_maintained_image.png\" alt=\"\" class=\"wp-image-227\" srcset=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/aspect_maintained_image.png 517w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/aspect_maintained_image-300x70.png 300w\" sizes=\"(max-width: 517px) 100vw, 517px\" \/><\/figure>\n\n\n\n<p>Here is the code to do that<\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">def image_resize(image, resize=None):\n    if resize is None:\n        h = config.IMAGE_HEIGHT\n        w = config.IMAGE_WIDTH\n    else:\n        h = resize[1]\n        w = resize[0]\n    image = tf.image.resize(image, size=(h, w), preserve_aspect_ratio=True)\n\n    # Check tha amount of padding needed to be done.\n\n    pad_height = h - tf.shape(image)[0]\n    pad_width = w - tf.shape(image)[1]\n\n    # Only necessary if you want to do same amount of padding on both sides.\n\n    if pad_height % 2 != 0:\n        height = pad_height \/\/ 2\n        pad_height_top = height + 1\n        pad_height_bottom = height\n    else:\n        pad_height_top = pad_height_bottom = pad_height \/\/ 2\n\n    if pad_width % 2 != 0:\n        width = pad_width \/\/ 2\n        pad_width_left = width + 1\n        pad_width_right = width\n    else:\n        pad_width_left = pad_width_right = pad_width \/\/ 2\n\n    image = tf.pad(\n        image,\n        paddings=[\n            [pad_height_top, pad_height_bottom],\n            [pad_width_left, pad_width_right],\n            [0, 0],\n        ],\n    )\n\n    \n    return imagedef image_resize(image, resize=None):<\/pre>\n\n\n\n<p>this is available on Keras website as well.<\/p>\n\n\n\n<h5 class=\"wp-block-heading\">Transpose the Image<\/h5>\n\n\n\n<p>Keras accepts images with shape (width, height, channels) so if our image is in any other shape, we have to change it<\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">def transpose_image(image, perm=None):\n    if perm is not None:\n        return tf.transpose(image, perm=perm)\n    else:\n        print(\"'perm' cannot be None, pass values such as `[1, 0, 2]`\")<\/pre>\n\n\n\n<h5 class=\"wp-block-heading\">Flip the Image<\/h5>\n\n\n\n<p>After we transpose the image, it generally gets flipped so we need to fix that as well.<\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">def flip_left_to_right(image):\n    return tf.image.flip_left_right(image)<\/pre>\n\n\n\n<p>your function will depend on how your image is flipped.<\/p>\n\n\n\n<p>At last, we are done with image processing<\/p>\n\n\n\n<p>Now let\u2019s start with label processing<\/p>\n\n\n\n<h4 class=\"wp-block-heading\">Text Processing<\/h4>\n\n\n\n<p>Why do we need text processing? And the answer is as always model does not recognize text data.<\/p>\n\n\n\n<p>If you know a little bit about classification problems in Machine learning you know that we use One Hot Encoding to get the text data to numbers.<\/p>\n\n\n\n<p>Can we do that here? And the answer is No. But why? Because we have a lot so samples in some cases billions of samples so if we use one-hot encoding, we will have to process a vector with billions of features for one word and this is not feasible and not efficient. So, we use some NLP techniques to encode our word to vector we will know more about it in future blogs. But for now, we will do simple tokenization.<\/p>\n\n\n\n<h5 class=\"wp-block-heading\">Get vocabulary<\/h5>\n\n\n\n<p>First, we will get the vocabulary of characters which means getting the unique characters in our training sample. We will use the set function here<\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">def set_vocabulary(self, dataframe):\n    self.characters = set(char for label in dataframe for char in label)<\/pre>\n\n\n\n<p>the set function returns a list of characters.<\/p>\n\n\n\n<h5 class=\"wp-block-heading\">Convert Characters to Number<\/h5>\n\n\n\n<p>We can do this by using TensorFlow inbuilt function<\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">def set_char_to_num(self):\n    self.char_to_num = tf.keras.layers.StringLookup(vocabulary=list(self.characters), mask_token=None)<\/pre>\n\n\n\n<p>we can get the character from number by using an argument in the StringLookup invert=True<\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">def set_num_to_char(self):\n    self.num_to_char = tf.keras.layers.StringLookup(vocabulary=self.char_to_num.get_vocabulary(),mask_token=None, invert=True)<\/pre>\n\n\n\n<p>Now let\u2019s make the dataset<\/p>\n\n\n\n<h4 class=\"wp-block-heading\">Making Dataset<\/h4>\n\n\n\n<p>There is a TensorFlow API that helps us handle large datasets. I will not go into detail here, but you can read more about it at TensorFlow Documentation.<\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">def get_dataset(self, image_paths, labels):\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n    dataset = (dataset.map(self.get_data_object, num_parallel_calls=tf.data.AUTOTUNE)) \\\n        .batch(config.BATCH_SIZE) \\\n        .cache() \\\n        .prefetch(buffer_size=tf.data.AUTOTUNE) \\\n\n    return dataset<\/pre>\n\n\n\n<p>from_tensor_slices is a function in the TensorFlow that takes the List and makes a tensor dataset object from it. Then in the next line, we can see that there are a few words like batch, cache, prefetch and AUTOTUNE. These are the functions that help us do parallel calls from the CPU while GPU is training the data.<\/p>\n\n\n\n<p>Now that we have our dataset let&#8217;s create our model.<\/p>\n\n\n\n<h4 class=\"wp-block-heading\">Model Creation<\/h4>\n\n\n\n<p>As we know we will use CNN and RNN for this project, this<\/p>\n\n\n\n<figure class=\"wp-block-image size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/model-812x1024.png\" alt=\"\" class=\"wp-image-228\" width=\"462\" height=\"583\" srcset=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/model-812x1024.png 812w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/model-238x300.png 238w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/model-768x968.png 768w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/model-444x560.png 444w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/model-167x210.png 167w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/model.png 936w\" sizes=\"(max-width: 462px) 100vw, 462px\" \/><\/figure>\n\n\n\n<p>Here we as you can see most of the layers are familiar but not the CTC loss layer<\/p>\n\n\n\n<p>CTC or Connectionist Temporal Classification is a technique used in sequence models like handwriting recognition speech recognition where the computer does not know how to align the characters.<\/p>\n\n\n\n<p>For example, Consider the word \u2019Hello\u2019 our model get the output in 10 timesteps \u2018HHellllloo\u2019, now one option is to collapse all the time step and we get \u2018Helo\u2019 which is wrong so CTC introduces a token for every time step \u2019HH|e|l||l|o|\u2019 which after collapse becomes \u2018Hello\u2019, now this is a small introduction to CTC Layer.<\/p>\n\n\n\n<p>I have posted my project on GitHub you can find the model code in the model.py file. &nbsp;I have used TensorFlow\u2019s functional API to make the model.<\/p>\n\n\n\n<p>Let\u2019s look at the layers<\/p>\n\n\n\n<h5 class=\"wp-block-heading\">Conv2D<\/h5>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">tf.keras.layers.Conv2D(filters=32,\n                           kernel_size=(3, 3),\n                           activation='relu',\n                           kernel_initializer='he_normal',\n                           padding=\"same\",\n                           name='Conv2D_1')(image)<\/pre>\n\n\n\n<p>Kernel size here means our filter size and as we know filters are used to detect features we get 32 features from this layer, kernel_initailizer is the initial weights of the network, padding=\u2019same\u2019 get the same image back without losing corners.<\/p>\n\n\n\n<h5 class=\"wp-block-heading\">Max Pooling<\/h5>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">tf.keras.layers.MaxPooling2D((2, 2), name=\"MaxPooling2D_1\")(x)<\/pre>\n\n\n\n<p>here we are reducing the size of the image to half-width and half-length.<\/p>\n\n\n\n<h5 class=\"wp-block-heading\">Reshape<\/h5>\n\n\n\n<p>We need to reshape the data to feed it into our ANN<\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">new_shape = ((config.IMAGE_WIDTH \/\/ 4), (config.IMAGE_HEIGHT \/\/ 4) * 64)\ntf.keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)<\/pre>\n\n\n\n<p>new_shape here is the width and height we divide it by 4 because we used MaxPooling twice we multiply it by 64 because our features are 64 after the second Conv2D, you can look at the full code in my GitHub repository.<\/p>\n\n\n\n<h5 class=\"wp-block-heading\">LSTM<\/h5>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.25))(x)<\/pre>\n\n\n\n<p>`return_sequences=True` means it will return the sequences instead of output it is essential if we are going to stack up the RNN<\/p>\n\n\n\n<p>Again, for a complete model look at my GitHub repository. I will add a link at the end.<\/p>\n\n\n\n<p>Now we have the dataset done, the Model done.<\/p>\n\n\n\n<p>We can go for training, right? Not quite, see OCR models don\u2019t use traditional Metrics like MSE, MAD, RMSE, etc. We use Edit distance which is the distance between the words. We can calculate it by using TensorFlow inbuilt functions. We need to send a callback to print edit distance after every epoch<\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">def calculate_edit_distance(sources, predictions, max_len):\n    sources_s_tensor = tf.cast(tf.sparse.from_dense(sources), dtype=tf.int64)\n    input_len = np.ones(predictions.shape[0]) * predictions.shape[1]\n    predictions_decoded = tf.keras.backend.ctc_decode(predictions, input_length=input_len, greedy=True)[0][0] \\\n\n        [:, :max_len]\n\n    predictions_s_tensor = tf.cast(tf.sparse.from_dense(predictions_decoded), dtype=tf.int64)\n    edit_distances = tf.edit_distance(predictions_s_tensor, sources_s_tensor, normalize=False)\n    return tf.reduce_mean(edit_distances)\n\n\nclass EditDistanceCallback(tf.keras.callbacks.Callback):\n    def __init__(self, pred_model, valid_dataset, max_len):\n        super().__init__()\n        self.prediction_model = pred_model\n        self.valid_dataset = valid_dataset\n        self.max_len = max_len\n\n    def on_epoch_end(self, epoch, logs=None):\n        edit_distances = []\n        validation_images = []\n        validation_labels = []\n\n        for batch in self.valid_dataset:\n            validation_images.append(batch[\"image\"])\n            validation_labels.append(batch[\"label\"])\n\n        for i in range(len(validation_images)):\n            labels = validation_labels[i]\n            predictions = self.prediction_model.predict(validation_images[i])\n            edit_distances.append(calculate_edit_distance(labels, predictions, self.max_len).numpy())\n\n        print(\n            f\"   Mean edit distance for epoch {epoch + 1}: {np.mean(edit_distances):.4f}\"\n        )<\/pre>\n\n\n\n<p>Now Let\u2019s Train<\/p>\n\n\n\n<p>I am training my dataset with 5 epochs for good accuracy train with 50 epochs<\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">model = model_obj.handwriting_recognition()\nprediction_model = tf.keras.models.Model(\n    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output\n)\nedit_distance_callback = metrics.EditDistanceCallback(prediction_model,valid_dataset,tp_obj.max_length)\n\n\n#Train the model\nhistory = model.fit(\n    train_dataset,\n    validation_data=valid_dataset,\n    epochs=config.EPOCHS,\n    callbacks=[edit_distance_callback],\n    batch_size=config.BATCH_SIZE\n)<\/pre>\n\n\n\n<figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"368\" src=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/model_training-1024x368.png\" alt=\"\" class=\"wp-image-232\" srcset=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/model_training-1024x368.png 1024w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/model_training-300x108.png 300w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/model_training-768x276.png 768w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/model_training-800x287.png 800w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/model_training.png 1200w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" \/><\/figure>\n\n\n\n<p>After training let&#8217;s look at some predictions<\/p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"507\" src=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/model_prediction-1024x507.png\" alt=\"\" class=\"wp-image-233\" srcset=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/model_prediction-1024x507.png 1024w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/model_prediction-300x149.png 300w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/model_prediction-768x380.png 768w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/model_prediction-800x396.png 800w, https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/model_prediction.png 1117w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" \/><\/figure>\n\n\n\n<p>as we can see our model is pretty accurate with just 5 epochs<\/p>\n\n\n\n<hr class=\"wp-block-separator\"\/>\n\n\n\n<h3 class=\"wp-block-heading\">Summary<\/h3>\n\n\n\n<p>We learned the basics of CNN and RNN then we learn how to prepare the dataset with TensorFlow API then we learned. After that, we build the CRNN model and trained it with 5 epochs. <\/p>\n\n\n\n<p>My Github Repository link: <a href=\"https:\/\/github.com\/kanavdawra\/Handwriting_Recognition\" target=\"_blank\" rel=\"noreferrer noopener\">https:\/\/github.com\/kanavdawra\/Handwriting_Recognition<\/a><\/p>\n\n\n\n<h3 class=\"wp-block-heading\">References<\/h3>\n\n\n\n<ol><li><a href=\"https:\/\/www.ripublication.com\/ijaer18\/ijaerv13n2_44.pdf\">https:\/\/www.ripublication.com\/ijaer18\/ijaerv13n2_44.pdf<\/a><\/li><li><a href=\"https:\/\/keras.io\/examples\/vision\/handwriting_recognition\/#prepare-tfdatadataset-objects\">https:\/\/keras.io\/examples\/vision\/handwriting_recognition\/#prepare-tfdatadataset-objects<\/a><\/li><\/ol>\n","protected":false},"excerpt":{"rendered":"<p>What is Handwriting recognition? Well, Handwriting recognition or Handwriting Text Recognition is the ability of a computer to read the text source which is written by hand. As the source is illegible to the computer there are some techniques that give the computer the ability to read the text. Some are: Convolutional Neural Network Method [&hellip;]<\/p>\n","protected":false},"author":1,"featured_media":234,"comment_status":"open","ping_status":"open","sticky":false,"template":"single.php","format":"standard","meta":{"spay_email":"","footnotes":""},"categories":[3],"tags":[],"yoast_head":"<!-- This site is optimized with the Yoast SEO plugin v21.8 - https:\/\/yoast.com\/wordpress\/plugins\/seo\/ -->\n<title>A Robust Explanation of Handwriting Recognition - CRNN - Kanav Dawra<\/title>\n<meta name=\"robots\" content=\"index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1\" \/>\n<link rel=\"canonical\" href=\"https:\/\/kanavdawra.com\/blog\/a-robust-explanation-of-handwriting-recognition-crnn\/\" \/>\n<meta property=\"og:locale\" content=\"en_US\" \/>\n<meta property=\"og:type\" content=\"article\" \/>\n<meta property=\"og:title\" content=\"A Robust Explanation of Handwriting Recognition - CRNN - Kanav Dawra\" \/>\n<meta property=\"og:description\" content=\"What is Handwriting recognition? Well, Handwriting recognition or Handwriting Text Recognition is the ability of a computer to read the text source which is written by hand. As the source is illegible to the computer there are some techniques that give the computer the ability to read the text. Some are: Convolutional Neural Network Method [&hellip;]\" \/>\n<meta property=\"og:url\" content=\"https:\/\/kanavdawra.com\/blog\/a-robust-explanation-of-handwriting-recognition-crnn\/\" \/>\n<meta property=\"og:site_name\" content=\"Kanav Dawra\" \/>\n<meta property=\"article:published_time\" content=\"2021-11-26T03:02:13+00:00\" \/>\n<meta property=\"article:modified_time\" content=\"2021-12-10T04:57:02+00:00\" \/>\n<meta property=\"og:image\" content=\"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/1_thumbnail.png\" \/>\n\t<meta property=\"og:image:width\" content=\"1280\" \/>\n\t<meta property=\"og:image:height\" content=\"720\" \/>\n\t<meta property=\"og:image:type\" content=\"image\/png\" \/>\n<meta name=\"author\" content=\"kanavdawra_admin-716\" \/>\n<meta name=\"twitter:card\" content=\"summary_large_image\" \/>\n<meta name=\"twitter:label1\" content=\"Written by\" \/>\n\t<meta name=\"twitter:data1\" content=\"kanavdawra_admin-716\" \/>\n\t<meta name=\"twitter:label2\" content=\"Est. reading time\" \/>\n\t<meta name=\"twitter:data2\" content=\"13 minutes\" \/>\n<script type=\"application\/ld+json\" class=\"yoast-schema-graph\">{\"@context\":\"https:\/\/schema.org\",\"@graph\":[{\"@type\":\"WebPage\",\"@id\":\"https:\/\/kanavdawra.com\/blog\/a-robust-explanation-of-handwriting-recognition-crnn\/\",\"url\":\"https:\/\/kanavdawra.com\/blog\/a-robust-explanation-of-handwriting-recognition-crnn\/\",\"name\":\"A Robust Explanation of Handwriting Recognition - CRNN - Kanav Dawra\",\"isPartOf\":{\"@id\":\"https:\/\/kanavdawra.com\/#website\"},\"datePublished\":\"2021-11-26T03:02:13+00:00\",\"dateModified\":\"2021-12-10T04:57:02+00:00\",\"author\":{\"@id\":\"https:\/\/kanavdawra.com\/#\/schema\/person\/465cae08f44cccb05b5d7c55beb512ce\"},\"breadcrumb\":{\"@id\":\"https:\/\/kanavdawra.com\/blog\/a-robust-explanation-of-handwriting-recognition-crnn\/#breadcrumb\"},\"inLanguage\":\"en-US\",\"potentialAction\":[{\"@type\":\"ReadAction\",\"target\":[\"https:\/\/kanavdawra.com\/blog\/a-robust-explanation-of-handwriting-recognition-crnn\/\"]}]},{\"@type\":\"BreadcrumbList\",\"@id\":\"https:\/\/kanavdawra.com\/blog\/a-robust-explanation-of-handwriting-recognition-crnn\/#breadcrumb\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"Home\",\"item\":\"https:\/\/kanavdawra.com\/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"A Robust Explanation of Handwriting Recognition &#8211; CRNN\"}]},{\"@type\":\"WebSite\",\"@id\":\"https:\/\/kanavdawra.com\/#website\",\"url\":\"https:\/\/kanavdawra.com\/\",\"name\":\"Kanav Dawra\",\"description\":\"Data Science\",\"potentialAction\":[{\"@type\":\"SearchAction\",\"target\":{\"@type\":\"EntryPoint\",\"urlTemplate\":\"https:\/\/kanavdawra.com\/?s={search_term_string}\"},\"query-input\":\"required name=search_term_string\"}],\"inLanguage\":\"en-US\"},{\"@type\":\"Person\",\"@id\":\"https:\/\/kanavdawra.com\/#\/schema\/person\/465cae08f44cccb05b5d7c55beb512ce\",\"name\":\"kanavdawra_admin-716\",\"image\":{\"@type\":\"ImageObject\",\"inLanguage\":\"en-US\",\"@id\":\"https:\/\/kanavdawra.com\/#\/schema\/person\/image\/\",\"url\":\"https:\/\/secure.gravatar.com\/avatar\/9ee5994c2536fd1d22469184c8b4680d?s=96&d=mm&r=g\",\"contentUrl\":\"https:\/\/secure.gravatar.com\/avatar\/9ee5994c2536fd1d22469184c8b4680d?s=96&d=mm&r=g\",\"caption\":\"kanavdawra_admin-716\"},\"sameAs\":[\"https:\/\/kanavdawra.com\"],\"url\":\"https:\/\/kanavdawra.com\/author\/kanavdawra_admin-716\/\"}]}<\/script>\n<!-- \/ Yoast SEO plugin. -->","yoast_head_json":{"title":"A Robust Explanation of Handwriting Recognition - CRNN - Kanav Dawra","robots":{"index":"index","follow":"follow","max-snippet":"max-snippet:-1","max-image-preview":"max-image-preview:large","max-video-preview":"max-video-preview:-1"},"canonical":"https:\/\/kanavdawra.com\/blog\/a-robust-explanation-of-handwriting-recognition-crnn\/","og_locale":"en_US","og_type":"article","og_title":"A Robust Explanation of Handwriting Recognition - CRNN - Kanav Dawra","og_description":"What is Handwriting recognition? Well, Handwriting recognition or Handwriting Text Recognition is the ability of a computer to read the text source which is written by hand. As the source is illegible to the computer there are some techniques that give the computer the ability to read the text. Some are: Convolutional Neural Network Method [&hellip;]","og_url":"https:\/\/kanavdawra.com\/blog\/a-robust-explanation-of-handwriting-recognition-crnn\/","og_site_name":"Kanav Dawra","article_published_time":"2021-11-26T03:02:13+00:00","article_modified_time":"2021-12-10T04:57:02+00:00","og_image":[{"width":1280,"height":720,"url":"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/1_thumbnail.png","type":"image\/png"}],"author":"kanavdawra_admin-716","twitter_card":"summary_large_image","twitter_misc":{"Written by":"kanavdawra_admin-716","Est. reading time":"13 minutes"},"schema":{"@context":"https:\/\/schema.org","@graph":[{"@type":"WebPage","@id":"https:\/\/kanavdawra.com\/blog\/a-robust-explanation-of-handwriting-recognition-crnn\/","url":"https:\/\/kanavdawra.com\/blog\/a-robust-explanation-of-handwriting-recognition-crnn\/","name":"A Robust Explanation of Handwriting Recognition - CRNN - Kanav Dawra","isPartOf":{"@id":"https:\/\/kanavdawra.com\/#website"},"datePublished":"2021-11-26T03:02:13+00:00","dateModified":"2021-12-10T04:57:02+00:00","author":{"@id":"https:\/\/kanavdawra.com\/#\/schema\/person\/465cae08f44cccb05b5d7c55beb512ce"},"breadcrumb":{"@id":"https:\/\/kanavdawra.com\/blog\/a-robust-explanation-of-handwriting-recognition-crnn\/#breadcrumb"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https:\/\/kanavdawra.com\/blog\/a-robust-explanation-of-handwriting-recognition-crnn\/"]}]},{"@type":"BreadcrumbList","@id":"https:\/\/kanavdawra.com\/blog\/a-robust-explanation-of-handwriting-recognition-crnn\/#breadcrumb","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https:\/\/kanavdawra.com\/"},{"@type":"ListItem","position":2,"name":"A Robust Explanation of Handwriting Recognition &#8211; CRNN"}]},{"@type":"WebSite","@id":"https:\/\/kanavdawra.com\/#website","url":"https:\/\/kanavdawra.com\/","name":"Kanav Dawra","description":"Data Science","potentialAction":[{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https:\/\/kanavdawra.com\/?s={search_term_string}"},"query-input":"required name=search_term_string"}],"inLanguage":"en-US"},{"@type":"Person","@id":"https:\/\/kanavdawra.com\/#\/schema\/person\/465cae08f44cccb05b5d7c55beb512ce","name":"kanavdawra_admin-716","image":{"@type":"ImageObject","inLanguage":"en-US","@id":"https:\/\/kanavdawra.com\/#\/schema\/person\/image\/","url":"https:\/\/secure.gravatar.com\/avatar\/9ee5994c2536fd1d22469184c8b4680d?s=96&d=mm&r=g","contentUrl":"https:\/\/secure.gravatar.com\/avatar\/9ee5994c2536fd1d22469184c8b4680d?s=96&d=mm&r=g","caption":"kanavdawra_admin-716"},"sameAs":["https:\/\/kanavdawra.com"],"url":"https:\/\/kanavdawra.com\/author\/kanavdawra_admin-716\/"}]}},"jetpack_featured_media_url":"https:\/\/kanavdawra.com\/wp-content\/uploads\/2021\/11\/1_thumbnail.png","acf":[],"_links":{"self":[{"href":"https:\/\/kanavdawra.com\/wp-json\/wp\/v2\/posts\/219"}],"collection":[{"href":"https:\/\/kanavdawra.com\/wp-json\/wp\/v2\/posts"}],"about":[{"href":"https:\/\/kanavdawra.com\/wp-json\/wp\/v2\/types\/post"}],"author":[{"embeddable":true,"href":"https:\/\/kanavdawra.com\/wp-json\/wp\/v2\/users\/1"}],"replies":[{"embeddable":true,"href":"https:\/\/kanavdawra.com\/wp-json\/wp\/v2\/comments?post=219"}],"version-history":[{"count":16,"href":"https:\/\/kanavdawra.com\/wp-json\/wp\/v2\/posts\/219\/revisions"}],"predecessor-version":[{"id":269,"href":"https:\/\/kanavdawra.com\/wp-json\/wp\/v2\/posts\/219\/revisions\/269"}],"wp:featuredmedia":[{"embeddable":true,"href":"https:\/\/kanavdawra.com\/wp-json\/wp\/v2\/media\/234"}],"wp:attachment":[{"href":"https:\/\/kanavdawra.com\/wp-json\/wp\/v2\/media?parent=219"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https:\/\/kanavdawra.com\/wp-json\/wp\/v2\/categories?post=219"},{"taxonomy":"post_tag","embeddable":true,"href":"https:\/\/kanavdawra.com\/wp-json\/wp\/v2\/tags?post=219"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}